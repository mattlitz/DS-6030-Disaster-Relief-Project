---
title: "Disaster Relief Project: Part I"
author: "Add your name here"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    number_sections: true    
    toc: true
    toc_float: true
    theme: cosmo
    highlight: espresso    
# You can make the format personal - this will get you started:  
# https://bookdown.org/yihui/rmarkdown/html-document.html#appearance_and_style    
---

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 5.5,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=TRUE)      # show R messages
```

<!--- Change font sizes (or other css modifications) --->
<style>
h1.title {
  font-size: 2.2em; /* Title font size */
}
h1 {
  font-size: 2em;   /* Header 1 font size */
}
h2 {
  font-size: 1.5em;
}
h3 { 
  font-size: 1.2em;
}
pre {
  font-size: 0.8em;  /* Code and R output font size */
}
</style>



**SYS 6018 | Spring 2021 | University of Virginia **

*******************************************

# Introduction 

Tell the reader what this project is about. Motivation. 

# Training Data / EDA

Load data, explore data, etc. 

```{r load-packages, warning=FALSE, message=FALSE}
# Load Required Packages
library(tidyverse)
library(readr)

data <- read_csv('HaitiPixels.csv')
attach(data)

data <- data %>% 
  mutate(BlueTarp = if_else(Class == "Blue Tarp", 1, 0))


data

ggplot(data, aes(x=factor(Class), y=Blue)) + 
  geom_boxplot(fill="orange", color="blue") + 
  labs(x="Class", y="Blue")

ggplot(data, aes(x=factor(Class), yinsta=Red)) + 
  geom_boxplot(fill="orange", color="blue") + 
  labs(x="Class", y="Red")

ggplot(data, aes(x=factor(Class), y=BlueTarp)) + 
  geom_boxplot(fill="orange", color="blue") + 
  labs(x="Class", y="Green")



```


# Model Training

## Set-up
```{r setup, echo=FALSE, message=FALSE}
library(broom)
library(tidymodels)
library(randomForest)
library(klaR)
library(caret)
library(glmnet)
library(class)

#Create training and test splits
train.rows <- sample(rownames(data), dim(data)[1]*0.6)

train <- data[train.rows, ]
test <- data[setdiff(rownames(data), train.rows), ]
c(dim(train)[1], dim(test)[1])


```


## Logistic Regression

```{r logistic, echo=TRUE, collapse = TRUE}

#train$Class = as.factor(train$Class)
#levels(train$Class) <- c('Blue_Tarp', 'Rooftop','Soil','Various_Non_Tarp','Vegetation')

train$BlueTarp = as.factor(train$BlueTarp)
levels(train$BlueTarp) <- c("1","0")

lambdas = 10^seq(0, -4, by=-0.1)

trControl = caret::trainControl(method='cv',
                                number=10,
                                savePredictions=TRUE, # required for thresholder
                                classProbs=TRUE,      # required for thresholder
                                allowParallel=TRUE)
tuneGrid = expand.grid(lambda=lambdas, alpha=0)
modelFit = caret::train(BlueTarp ~ ., data=subset(train, select = -c(Class)),
                 method='glmnet',
                 family='binomial',  # set the family for logistic regression
                 thresh=0.25,        # set the threshold
                 trControl=trControl,
                 tuneGrid=tuneGrid)


```






## LDA

```{r LDA}
set.seed(17)
#train

#lda.fit <- lda(Class~Red+Blue+Green, data=data, subset=train)
#lda.fit


kfolds_lda.fit <- function(p, data, kfolds) {
  mod_form <- paste0("Class~Red+Blue+Green")        
  caret::train(as.formula(mod_form), data=data, trControl=kfolds, method="lda")
}


train_control <- caret::trainControl(method="cv", number=10, 
                                     savePredictions=TRUE)
models <- purrr::set_names(as.character(1:1)) %>% 
  purrr::map(kfolds_lda.fit, data, train_control)
models

purrr::map(models, (function(x) x$resample))

library(klaR)
partimat(Class ~ ., data = data, method = "lda", plot.matrix = TRUE, col.correct='green', col.wrong='red')


```






## QDA

```{r qda, echo=TRUE, collapse = TRUE}






qda.fit <- qda(BlueTarp~Red + Green + Blue, data=train)
qda.fit 


qda.pred <- tibble(prediction=predict(qda.fit, test)$class) %>% 
  add_column(test %>% dplyr::select(BlueTarp)) 
qda.pred %>% conf_mat(BlueTarp, prediction)


qda.pred %>% mutate(correct = as.numeric(prediction==BlueTarp)) %>% 
  dplyr::select(correct) %>% colMeans()


```

## KNN

```{r knn, echo=TRUE, collapse = TRUE}

X.train <- train %>% dplyr::select(Red, Green, Blue) %>% 
  as.matrix()
X.test <- train %>% dplyr::select(Red, Green, Blue) %>% 
  as.matrix()
Y.train <- train %>% dplyr::select(BlueTarp) %>% 
  as.matrix()
set.seed(1)
#knn.pred=knn(train.X,test.X,train.Direction,k=1)
#table(knn.pred,Direction.2005)
Y.test <- train %>% dplyr::select(BlueTarp)
tibble(yhat = knn(X.train, X.test, Y.train, k=1), y = Y.test[['BlueTarp']]) %>%
  conf_mat(y, yhat)


tibble(yhat = knn(X.train, X.test, Y.train, k=1), y = Y.test[['BlueTarp']]) %>%
  mutate(correct = as.numeric(yhat==y)) %>% 
  dplyr::select(correct) %>% colMeans()


tibble(yhat = knn(X.train, X.test, Y.train, k=3), y = Y.test[['BlueTarp']]) %>%
  conf_mat(y, yhat)


tibble(yhat = knn(X.train, X.test, Y.train, k=3), y = Y.test[['BlueTarp']]) %>%
  mutate(correct = as.numeric(yhat==y)) %>% 
  dplyr::select(correct) %>% colMeans()

```


### Tuning Parameter $k$

How were tuning parameter(s) selected? What value is used? Plots/Tables/etc.

## Penalized Logistic Regression (ElasticNet)






### Tuning Parameters





## Threshold Selection

```{r threshold}

#Given a tuned model, you can explore different threshold values using caret::thresholder

probs <- seq(.1, 0.9, by = 0.02)

ths <- thresholder(modelFit,
                   threshold = probs,
                   final = TRUE,
                   statistics = "all")
plot(ths$prob_threshold, ths$Accuracy)

```







# Results (Cross-Validation)

** CV Performance Table Here**


# Conclusions

### Conclusion \#1 

### Conclusion \#2

### Conclusion \#3

